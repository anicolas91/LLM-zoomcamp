{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate retrieval metrics for text\n",
    "From the ChatGPT generated faqs, we are going to evaluate if we can retrieve the relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the data with all 5 faqs per doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the 5 faqs w ids for each question\n",
    "with open('documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreanicolas/anaconda3/envs/llm_env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# different pre-trained models available, we will use cosine similarity\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length is 384\n"
     ]
    }
   ],
   "source": [
    "# test it\n",
    "v = model.encode('I just discovered the course, can I still join?')\n",
    "print(f'length is {len(v)}')\n",
    "\n",
    "#notes: this vector, when comparing to others, will get a max of 1 during dot prduct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. setup Elasticsearch for vectorization indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up elasticsearch\n",
    "# we want a vector for question, answer and q+a\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\"type\":\"dense_vector\",\"dims\":384,\"index\":True,\"similarity\":\"cosine\"},\n",
    "            \"text_vector\": {\"type\":\"dense_vector\",\"dims\":384,\"index\":True,\"similarity\":\"cosine\"},\n",
    "            \"question_text_vector\": {\"type\":\"dense_vector\",\"dims\":384,\"index\":True,\"similarity\":\"cosine\"},\n",
    "\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "# create index, make sure you have new one\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. vectorize q, a, q+a and index w/elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c258de5170354f59838f9a91926324a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vectorize\n",
    "for doc in tqdm(documents):\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    qt = question + ' ' + text\n",
    "    doc['question_vector'] = model.encode(question)\n",
    "    doc['text_vector'] = model.encode(text)\n",
    "    doc['question_text_vector'] = model.encode(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c3ad862d9b463c9e7b12969a605870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#index it\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. make an actual search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the proper query settings\n",
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5, #get me 5 nearest neighbors matching this search term\n",
    "        \"num_candidates\": 10000, #group of documents that search will look into\n",
    "        \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": course\n",
    "                }\n",
    "            }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "            \"knn\": knn,\n",
    "            \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "        }\n",
    "    # search properly using semantic search\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "        body =search_query,\n",
    "        )\n",
    "       \n",
    "    #parse results\n",
    "    result_docs = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full query from incoming text\n",
    "def question_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'id': '7842b56a'},\n",
       " {'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'id': '7842b56a'},\n",
       " {'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'id': 'a482086d'},\n",
       " {'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'id': 'a482086d'},\n",
       " {'question': 'How can we contribute to the course?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
       "  'id': '2f19301f'}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we try a proper query\n",
    "query = 'I just discovered the course. Can I still join it?'\n",
    "course = 'data-engineering-zoomcamp'\n",
    "q = {'question':query,\n",
    "     'course':course}\n",
    "\n",
    "response=question_vector_knn(q)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate against groound truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total):\n",
    "    ''' \n",
    "    This fcn evaluates hit rate\n",
    "    '''\n",
    "    cnt = 0\n",
    "    # count if any True found on line\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    '''\n",
    "    this fcn evaluates mean reciprocal rank\n",
    "    '''\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "                break\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    ''' \n",
    "    This function uses any specific search engine you set up to \n",
    "    check out the ground truch, and it evaluates the 2 metrics \n",
    "    '''\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pd.read_csv('ground-truth-data.csv')\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f6e6cc960a4bd7a7e88c70ddc3aeb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.7445429003674087, 'mrr': 0.6475542107917298}\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = evaluate(ground_truth, question_vector_knn)\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: evaluation metrics take time because we are vectorizing things\n",
    "These eval metrics do better than the pure text-only one we had done before. As a reference, it was, using minsearch:\n",
    "{'hit_rate': 0.7722066133563864, 'mrr': 0.661454506159499}\n",
    "\n",
    "\n",
    "Let's look now at other types of vectorizations and how they fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full query from incoming text\n",
    "def text_vector_knn(q):\n",
    "    question = q['question'] #remember this is the actual question on the faq\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a9d14eb8074cada44b31543d2f980e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.7983574670412794, 'mrr': 0.6850803256249559}\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = evaluate(ground_truth, text_vector_knn)\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-text vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full query from incoming text\n",
    "def question_text_vector_knn(q):\n",
    "    question = q['question'] #remember this is the actual question on the faq\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35284fdaed0240a595f5817e80f85382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit_rate': 0.8960449535336071, 'mrr': 0.8064980909156398}\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = evaluate(ground_truth, question_text_vector_knn)\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alexey also looks at combining the vectorization as an actual parameter in elasticsearch.\n",
    "\n",
    "Have a look at how he did it (it is just using a code generated by ChatGPT):\n",
    "\n",
    "[jupyter notebook](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/03-vector-search/eval/evaluate-vector.ipynb)\n",
    "\n",
    "Overall it was a whole lot of effort for a worse performing search engine.\n",
    "\n",
    "Will not recreate it here for the sake of time, and to keep this notebook clean.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
