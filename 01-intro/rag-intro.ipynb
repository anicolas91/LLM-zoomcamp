{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "We basically first retrieve data using a search engine trained to our data, and then generate an answer based on that via LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-13 18:07:28--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py.2’\n",
      "\n",
      "minsearch.py.2      100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-13 18:07:28 (26.9 MB/s) - ‘minsearch.py.2’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch # alexeys small and fast search engine\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start and train search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json data \n",
    "# clean json dictionaries extracted by alexey grigorev using:\n",
    "# https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/parse-faq.ipynb\n",
    "# raw input data was the FAQ google documents for the mlops, ml, data engineering zoomcamp\n",
    "\n",
    "with open('documents.json','rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange data a bit (add course type to each faq)\n",
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course'] #adding it to every faq\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x17a57f9d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize class, tell the search engine what is searchable and what are keywords\n",
    "index = minsearch.Index(\n",
    "    text_fields=['text','section','question'],\n",
    "    keyword_fields=['course']\n",
    ")\n",
    "\n",
    "#actually train the search engine\n",
    "index.fit(docs=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aux fcns\n",
    "def search(query,filter_dict={'course': 'data-engineering-zoomcamp'}):\n",
    "    '''  \n",
    "    This function runs the already trained search engine and retrieves the top 5 results,\n",
    "    '''\n",
    "    boost = {'question': 3.0, 'section': 0.5} # what to stress on, what is more important. give it weights\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict=filter_dict,\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    ''' \n",
    "    This function starts with a prompt template, and given the query fills the template out with the results from the search engine\n",
    "    '''\n",
    "    # we will give the llm some context\n",
    "    # Alexey mentions that this is a bit of art and science because you somewhat iterate until you find something that works for you.\n",
    "    prompt_template =  \"\"\" \n",
    "\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. \n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    If the CONTEXT does not contain the answer, output NONE.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT: {context}\n",
    "\n",
    "    \"\"\".strip() #no line breaks\n",
    "    \n",
    "    #convert search results into proper formatted context\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer:{doc['text']}\\n\\n\"\n",
    "\n",
    "\n",
    "    # we formally add the info on the prompt\n",
    "    return prompt_template.format(question=query,context=context).strip()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt,model='gpt-4o-mini'):\n",
    "    ''' \n",
    "    This function trains chatGPT with our prompt (with the search engine results)\n",
    "    '''\n",
    "    # train openai/chatpgt with the prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        messages=[{'role':'user','content': prompt}]\n",
    "    )   \n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    '''  \n",
    "    This function, given a question, finds best answers on the search engine, trains the llm with it, and returns a result\n",
    "    '''\n",
    "    # search for the question on the search engine\n",
    "    results = search(q)\n",
    "    # we create the context by basically stringing together the answers from the search engine\n",
    "    prompt = build_prompt(q, results)\n",
    "    # we train the llm (in this case chatGPT) with the prompt and returns some user friendly answer\n",
    "    answer = llm(prompt)\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can still enroll in the course after the start date. Even if you don't register, you're still eligible to submit the homeworks. However, be aware that there will be deadlines for turning in the final projects, so it's advisable not to leave everything for the last minute.\n"
     ]
    }
   ],
   "source": [
    "q= 'The course just started. Can I still enroll?'\n",
    "answer = rag(q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch\n",
    "Data will persist, because you trained it before.\n",
    "This is what people formally use, we will use that to replace the toy `minsearch` engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the elastic search client\n",
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the elasticsearch engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'course-questions' already exists.\n"
     ]
    }
   ],
   "source": [
    "# now we set up the index on elasticsearch\n",
    "# this is the equivalent on minsearch to:\n",
    "# index = minsearch.Index(\n",
    "#     text_fields=['text','section','question'],\n",
    "#     keyword_fields=['course']\n",
    "# )\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = 'course-questions'\n",
    "\n",
    "if not es_client.indices.exists(index=index_name):\n",
    "    es_client.indices.create(index=index_name, body=index_settings)\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:01<00:00, 573.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# we now actually index the data\n",
    "# this is similar to the following in min search\n",
    "# index.fit(docs=documents)\n",
    "# note that you have to index every entry one by one\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name,document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redoing RAG with the pretrained elasticsearch engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a search query\n",
    "# this is the equivalent on minsearch to:\n",
    "# boost = {'question': 3.0, 'section': 0.5} # what to stress on, what is more important. give it weights\n",
    "#     results = index.search(\n",
    "#         query=query,\n",
    "#         filter_dict=filter_dict,\n",
    "#         boost_dict=boost,\n",
    "#         num_results=10\n",
    "#     )\n",
    "\n",
    "def elastic_search(query,n_results=5):\n",
    "    '''  \n",
    "    This function submits a query to the pretrained elastic search, and returns formatted results\n",
    "    default search results is 5\n",
    "    question is 3x important than text and section\n",
    "    '''\n",
    "\n",
    "    # create properly formatted search query that works with elasticsearch\n",
    "    search_query = {\n",
    "        \"size\": n_results, #no of search results\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"], # question is 3x more important than text and section\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\" # we filter by course name\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # search the pretrained client given the formatted query\n",
    "    response = es_client.search(index=index_name,body=search_query)\n",
    "\n",
    "    # return all the top results in a readable python list\n",
    "    result_docs = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    '''  \n",
    "    This function, given a question, finds best answers on the search engine, trains the llm with it, and returns a result\n",
    "    '''\n",
    "    # search for the question on the search engine\n",
    "    results = elastic_search(q)\n",
    "    # we create the context by basically stringing together the answers from the search engine\n",
    "    prompt = build_prompt(q, results)\n",
    "    # we train the llm (in this case chatGPT) with the prompt and returns some user friendly answer\n",
    "    answer = llm(prompt)\n",
    "\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can still enroll in the course after the start date. Even if you don't register, you're eligible to submit the homeworks. However, be aware that there will be deadlines for turning in the final projects. It's advised not to leave everything for the last minute.\n"
     ]
    }
   ],
   "source": [
    "answer = rag(q)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
